{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f91Zqmwdm7pw"
   },
   "outputs": [],
   "source": [
    "# For Sam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"Train.csv\")\n",
    "finaltest = pd.read_csv(\"Test.csv\")\n",
    "riders = pd.read_csv('Riders.csv')\n",
    "sample = pd.read_csv('SampleSubmission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order No</th>\n",
       "      <th>User Id</th>\n",
       "      <th>Vehicle Type</th>\n",
       "      <th>Platform Type</th>\n",
       "      <th>Personal or Business</th>\n",
       "      <th>Placement - Day of Month</th>\n",
       "      <th>Placement - Weekday (Mo = 1)</th>\n",
       "      <th>Placement - Time</th>\n",
       "      <th>Confirmation - Day of Month</th>\n",
       "      <th>Confirmation - Weekday (Mo = 1)</th>\n",
       "      <th>...</th>\n",
       "      <th>Arrival at Destination - Time</th>\n",
       "      <th>Distance (KM)</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Precipitation in millimeters</th>\n",
       "      <th>Pickup Lat</th>\n",
       "      <th>Pickup Long</th>\n",
       "      <th>Destination Lat</th>\n",
       "      <th>Destination Long</th>\n",
       "      <th>Rider Id</th>\n",
       "      <th>Time from Pickup to Arrival</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Order_No_4211</td>\n",
       "      <td>User_Id_633</td>\n",
       "      <td>Bike</td>\n",
       "      <td>3</td>\n",
       "      <td>Business</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>9:35:46 AM</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>10:39:55 AM</td>\n",
       "      <td>4</td>\n",
       "      <td>20.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.317755</td>\n",
       "      <td>36.830370</td>\n",
       "      <td>-1.300406</td>\n",
       "      <td>36.829741</td>\n",
       "      <td>Rider_Id_432</td>\n",
       "      <td>745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Order_No_25375</td>\n",
       "      <td>User_Id_2285</td>\n",
       "      <td>Bike</td>\n",
       "      <td>3</td>\n",
       "      <td>Personal</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>11:16:16 AM</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>12:17:22 PM</td>\n",
       "      <td>16</td>\n",
       "      <td>26.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.351453</td>\n",
       "      <td>36.899315</td>\n",
       "      <td>-1.295004</td>\n",
       "      <td>36.814358</td>\n",
       "      <td>Rider_Id_856</td>\n",
       "      <td>1993</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Order No       User Id Vehicle Type  Platform Type  \\\n",
       "0   Order_No_4211   User_Id_633         Bike              3   \n",
       "1  Order_No_25375  User_Id_2285         Bike              3   \n",
       "\n",
       "  Personal or Business  Placement - Day of Month  \\\n",
       "0             Business                         9   \n",
       "1             Personal                        12   \n",
       "\n",
       "   Placement - Weekday (Mo = 1) Placement - Time  Confirmation - Day of Month  \\\n",
       "0                             5       9:35:46 AM                            9   \n",
       "1                             5      11:16:16 AM                           12   \n",
       "\n",
       "   Confirmation - Weekday (Mo = 1)  ... Arrival at Destination - Time  \\\n",
       "0                                5  ...                   10:39:55 AM   \n",
       "1                                5  ...                   12:17:22 PM   \n",
       "\n",
       "   Distance (KM)  Temperature Precipitation in millimeters  Pickup Lat  \\\n",
       "0              4         20.4                          NaN   -1.317755   \n",
       "1             16         26.4                          NaN   -1.351453   \n",
       "\n",
       "   Pickup Long Destination Lat  Destination Long      Rider Id  \\\n",
       "0    36.830370       -1.300406         36.829741  Rider_Id_432   \n",
       "1    36.899315       -1.295004         36.814358  Rider_Id_856   \n",
       "\n",
       "  Time from Pickup to Arrival  \n",
       "0                         745  \n",
       "1                        1993  \n",
       "\n",
       "[2 rows x 29 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rider Id</th>\n",
       "      <th>No_Of_Orders</th>\n",
       "      <th>Age</th>\n",
       "      <th>Average_Rating</th>\n",
       "      <th>No_of_Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rider_Id_396</td>\n",
       "      <td>2946</td>\n",
       "      <td>2298</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rider_Id_479</td>\n",
       "      <td>360</td>\n",
       "      <td>951</td>\n",
       "      <td>13.5</td>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Rider Id  No_Of_Orders   Age  Average_Rating  No_of_Ratings\n",
       "0  Rider_Id_396          2946  2298            14.0           1159\n",
       "1  Rider_Id_479           360   951            13.5            176"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "riders.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order No</th>\n",
       "      <th>User Id</th>\n",
       "      <th>Vehicle Type</th>\n",
       "      <th>Platform Type</th>\n",
       "      <th>Personal or Business</th>\n",
       "      <th>Placement - Day of Month</th>\n",
       "      <th>Placement - Weekday (Mo = 1)</th>\n",
       "      <th>Placement - Time</th>\n",
       "      <th>Confirmation - Day of Month</th>\n",
       "      <th>Confirmation - Weekday (Mo = 1)</th>\n",
       "      <th>...</th>\n",
       "      <th>Pickup - Weekday (Mo = 1)</th>\n",
       "      <th>Pickup - Time</th>\n",
       "      <th>Distance (KM)</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Precipitation in millimeters</th>\n",
       "      <th>Pickup Lat</th>\n",
       "      <th>Pickup Long</th>\n",
       "      <th>Destination Lat</th>\n",
       "      <th>Destination Long</th>\n",
       "      <th>Rider Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Order_No_19248</td>\n",
       "      <td>User_Id_3355</td>\n",
       "      <td>Bike</td>\n",
       "      <td>3</td>\n",
       "      <td>Business</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>4:44:10 PM</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>5:06:47 PM</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.333275</td>\n",
       "      <td>36.870815</td>\n",
       "      <td>-1.305249</td>\n",
       "      <td>36.822390</td>\n",
       "      <td>Rider_Id_192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Order_No_12736</td>\n",
       "      <td>User_Id_3647</td>\n",
       "      <td>Bike</td>\n",
       "      <td>3</td>\n",
       "      <td>Business</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>12:57:35 PM</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>1:25:37 PM</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.272639</td>\n",
       "      <td>36.794723</td>\n",
       "      <td>-1.277007</td>\n",
       "      <td>36.823907</td>\n",
       "      <td>Rider_Id_868</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Order No       User Id Vehicle Type  Platform Type  \\\n",
       "0  Order_No_19248  User_Id_3355         Bike              3   \n",
       "1  Order_No_12736  User_Id_3647         Bike              3   \n",
       "\n",
       "  Personal or Business  Placement - Day of Month  \\\n",
       "0             Business                        27   \n",
       "1             Business                        17   \n",
       "\n",
       "   Placement - Weekday (Mo = 1) Placement - Time  Confirmation - Day of Month  \\\n",
       "0                             3       4:44:10 PM                           27   \n",
       "1                             5      12:57:35 PM                           17   \n",
       "\n",
       "   Confirmation - Weekday (Mo = 1)  ... Pickup - Weekday (Mo = 1)  \\\n",
       "0                                3  ...                         3   \n",
       "1                                5  ...                         5   \n",
       "\n",
       "   Pickup - Time  Distance (KM) Temperature  Precipitation in millimeters  \\\n",
       "0     5:06:47 PM              8         NaN                           NaN   \n",
       "1     1:25:37 PM              5         NaN                           NaN   \n",
       "\n",
       "   Pickup Lat Pickup Long  Destination Lat  Destination Long      Rider Id  \n",
       "0   -1.333275   36.870815        -1.305249         36.822390  Rider_Id_192  \n",
       "1   -1.272639   36.794723        -1.277007         36.823907  Rider_Id_868  \n",
       "\n",
       "[2 rows x 25 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaltest.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Arrival at Destination - Day of Month',\n",
       " 'Arrival at Destination - Time',\n",
       " 'Arrival at Destination - Weekday (Mo = 1)',\n",
       " 'Time from Pickup to Arrival'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(dataset.columns) - set(finaltest.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we must drop the above before moving on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "are the columns in the final that are not on training?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(finaltest.columns) - set(dataset.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The placement time of the order is irrelevant to the target. The main concern of the problem statement is the period between pickup and arrival. When the order was placed, has no bearing whatsoever in effect to that period. So, we are going to drop everything concerning placement. \n",
    "\n",
    "Furthermore, 'Confirmation' columns, with the same argument, must be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "placement = [col for col in dataset.columns if ((col[:len('Placement')] == 'Placement') or (col[:len('Confirmation')] == 'Confirmation')) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Placement - Day of Month',\n",
       " 'Placement - Weekday (Mo = 1)',\n",
       " 'Placement - Time',\n",
       " 'Confirmation - Day of Month',\n",
       " 'Confirmation - Weekday (Mo = 1)',\n",
       " 'Confirmation - Time']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "placement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdata = dataset.drop(columns=['Time from Pickup to Arrival', 'User Id', 'Order No', \n",
    "'Arrival at Destination - Day of Month',\n",
    "'Arrival at Destination - Time',\n",
    "'Arrival at Destination - Weekday (Mo = 1)'] + placement)\n",
    "X = xdata.copy() # I want to run this column everytime I want to restart after changes\n",
    "X = X.merge(riders, how='left', on=['Rider Id']).drop(columns=['Rider Id'])\n",
    "\n",
    "f_testx = finaltest.merge(riders, how='left', on=['Rider Id']).drop(columns=['User Id', 'Order No', 'Rider Id'] + placement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Platform Type', 'Personal or Business']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in f_testx.columns if x[:4] in  ['Pers', 'Plat']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dataset['Time from Pickup to Arrival'] # The target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm columns if columns on train are those on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(f_testx.columns) == set(X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now things are about to get ugly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START FUNCTION\n",
    "def cleaner(input_df, nullthreshold=0.9, correlation_thresh=0.95, day_of_month_cols=[], day_of_week_cols=[]):\n",
    "    input_dfc = input_df.copy()\n",
    "    \n",
    "\n",
    "    #########################################################################################\n",
    "    # The Code below drops columns that have null values exceeding threshold and Columns that have ONLY one value\n",
    "    for col in input_df.columns:\n",
    "        if (sum(input_df[col].isnull())/len(input_df[col]) > nullthreshold) or (len(input_df[col].unique()) == 1):\n",
    "            input_dfc.drop(columns=[col], inplace=True) \n",
    "            \n",
    "            \n",
    "    #########################################################################################\n",
    "\n",
    "    #########################################################################################\n",
    "    #This code converts time given by am and pm into seconds then applies cosine and sine\n",
    "    def time_to_seconds(input_df):\n",
    "        input_dfc = input_df.copy()\n",
    "\n",
    "        from datetime import datetime\n",
    "\n",
    "        for time_col in [col for col in input_df.columns if 'Time' in [col[-4:]]]:\n",
    "\n",
    "            input_dfc[time_col + '_sin(seconds)'] = \\\n",
    "            input_df[time_col].apply(lambda time: np.sin(\n",
    "                (datetime.strptime(time, '%I:%M:%S %p') - datetime(1900,1,1)).total_seconds() \\\n",
    "                * (2.*np.pi/86400) )) # there are 86400 seconds in a day\n",
    "\n",
    "            input_dfc[time_col + '_cos(seconds)'] = \\\n",
    "            input_df[time_col].apply(lambda time: np.cos(\n",
    "                (datetime.strptime(time, '%I:%M:%S %p') - datetime(1900,1,1)).total_seconds() \\\n",
    "                * (2.*np.pi/86400) ))\n",
    "\n",
    "            input_dfc.drop(columns=[time_col], inplace=True)\n",
    "\n",
    "        return input_dfc\n",
    "\n",
    "    input_dfc2 = time_to_seconds(input_dfc)\n",
    "    #########################################################################################\n",
    "    \n",
    "    #########################################################################################\n",
    "    # This code encodes ['Platform Type', 'Personal or Business']\n",
    "    \n",
    "    def one_encoder(input_df, columns):\n",
    "    \n",
    "        return pd.get_dummies(input_df, drop_first=True, columns=columns, dtype=float)\n",
    "\n",
    "    \n",
    "    input_dfc2 = one_encoder(input_dfc2, ['Platform Type', 'Personal or Business'])\n",
    "    #########################################################################################\n",
    "    def cyclic_days(input_df, month_days_cols, weekdays_cols):\n",
    "        input_dfc = input_df.copy()\n",
    "\n",
    "\n",
    "        for mday_col in month_days_cols:\n",
    "            if mday_col in input_dfc.columns:\n",
    "\n",
    "                input_dfc[mday_col + '_sin(day)'] = input_df[mday_col].apply(lambda day: np.sin(\\\n",
    "                day * (2.*np.pi/31))\\\n",
    "                    )\n",
    "\n",
    "                input_dfc[mday_col + '_cos(day)'] = input_df[mday_col].apply(lambda day: np.cos(\\\n",
    "                day * (2.*np.pi/31))\\\n",
    "                    )\n",
    "\n",
    "                input_dfc.drop(mday_col, inplace=True, axis=1)\n",
    "\n",
    "\n",
    "        for wday_col in weekdays_cols:\n",
    "            if wday_col in input_dfc.columns:\n",
    "\n",
    "                input_dfc[wday_col + '_sin(day)'] = input_df[wday_col].apply(lambda day: np.sin(\\\n",
    "                day * (2.*np.pi/7))\\\n",
    "                    )\n",
    "\n",
    "                input_dfc[wday_col + '_cos(day)'] = input_df[wday_col].apply(lambda day: np.cos(\\\n",
    "                day * (2.*np.pi/7))\\\n",
    "                    )\n",
    "\n",
    "                input_dfc.drop(wday_col, inplace=True, axis=1)\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        return input_dfc\n",
    "    \n",
    "    input_dfc2 = cyclic_days(input_dfc2, day_of_month_cols, day_of_week_cols)     \n",
    "    #########################################################################################\n",
    "    # This code will remove one of a pair of variables that are 95% correlated\n",
    "    def correlation_drop(df, thresh):\n",
    "        while True:\n",
    "            corr_matrix = df.corr(method = \"spearman\").abs()\n",
    "            upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k = 1).astype(np.bool))\n",
    "            to_drop = [column for column in upper.columns if any(upper[column] > thresh)]\n",
    "            if len(to_drop) == 0:\n",
    "                break\n",
    "            else:\n",
    "                #print(to_drop) \n",
    "                df = df.drop(to_drop, axis = 1)\n",
    "                print('dropped by corr', to_drop)\n",
    "           \n",
    "        return df\n",
    "    \n",
    "    input_dfc2 = correlation_drop(input_dfc2, correlation_thresh)\n",
    "    #########################################################################################\n",
    "\n",
    "    print(f\"Total of {len([x for x in input_df.columns if x not in input_dfc2.columns])} original columns dropped \\n\")  \n",
    "    print(f\"Total of {len([x for x in input_dfc2.columns if x not in input_df])} new CLEAN columns formed \\n\")\n",
    "    print(f\"Dataframe now has {len(input_dfc2.columns)} from {len(input_df.columns)} input columns\")\n",
    "    print([x for x in input_df.columns if x not in input_dfc2.columns])\n",
    "\n",
    "    return input_dfc2\n",
    "\n",
    "### END FUNCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we apply our ultimate cleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropped by corr ['Pickup - Time_sin(seconds)', 'Pickup - Time_cos(seconds)', 'Pickup - Day of Month_sin(day)', 'Pickup - Day of Month_cos(day)', 'Pickup - Weekday (Mo = 1)_sin(day)', 'Pickup - Weekday (Mo = 1)_cos(day)']\n",
      "Total of 10 original columns dropped \n",
      "\n",
      "Total of 10 new CLEAN columns formed \n",
      "\n",
      "Dataframe now has 20 from 20 input columns\n",
      "['Vehicle Type', 'Platform Type', 'Personal or Business', 'Arrival at Pickup - Day of Month', 'Arrival at Pickup - Weekday (Mo = 1)', 'Arrival at Pickup - Time', 'Pickup - Day of Month', 'Pickup - Weekday (Mo = 1)', 'Pickup - Time', 'Precipitation in millimeters']\n"
     ]
    }
   ],
   "source": [
    "day_of_month_cols = [x for x in X.columns if x[-5:] == 'Month']\n",
    "day_of_week_cols = [x for x in X.columns if x[-(len('(Mo = 1)')):] == '(Mo = 1)']\n",
    "X_train = cleaner(X_train, day_of_month_cols=day_of_month_cols, day_of_week_cols=day_of_week_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Arrival at Pickup - Weekday (Mo = 1)', 'Pickup - Weekday (Mo = 1)']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day_of_week_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Distance (KM)</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Pickup Lat</th>\n",
       "      <th>Pickup Long</th>\n",
       "      <th>Destination Lat</th>\n",
       "      <th>Destination Long</th>\n",
       "      <th>No_Of_Orders</th>\n",
       "      <th>Age</th>\n",
       "      <th>Average_Rating</th>\n",
       "      <th>No_of_Ratings</th>\n",
       "      <th>Arrival at Pickup - Time_sin(seconds)</th>\n",
       "      <th>Arrival at Pickup - Time_cos(seconds)</th>\n",
       "      <th>Platform Type_2</th>\n",
       "      <th>Platform Type_3</th>\n",
       "      <th>Platform Type_4</th>\n",
       "      <th>Personal or Business_Personal</th>\n",
       "      <th>Arrival at Pickup - Day of Month_sin(day)</th>\n",
       "      <th>Arrival at Pickup - Day of Month_cos(day)</th>\n",
       "      <th>Arrival at Pickup - Weekday (Mo = 1)_sin(day)</th>\n",
       "      <th>Arrival at Pickup - Weekday (Mo = 1)_cos(day)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5593</th>\n",
       "      <td>8</td>\n",
       "      <td>22.5</td>\n",
       "      <td>-1.300921</td>\n",
       "      <td>36.828195</td>\n",
       "      <td>-1.258711</td>\n",
       "      <td>36.834940</td>\n",
       "      <td>282</td>\n",
       "      <td>326</td>\n",
       "      <td>14.7</td>\n",
       "      <td>46</td>\n",
       "      <td>-0.674732</td>\n",
       "      <td>-0.738063</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.724793</td>\n",
       "      <td>0.688967</td>\n",
       "      <td>0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6873</th>\n",
       "      <td>5</td>\n",
       "      <td>23.2</td>\n",
       "      <td>-1.260234</td>\n",
       "      <td>36.799055</td>\n",
       "      <td>-1.256810</td>\n",
       "      <td>36.773083</td>\n",
       "      <td>235</td>\n",
       "      <td>740</td>\n",
       "      <td>13.5</td>\n",
       "      <td>24</td>\n",
       "      <td>0.411846</td>\n",
       "      <td>-0.911254</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.998717</td>\n",
       "      <td>-0.050649</td>\n",
       "      <td>-0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Distance (KM)  Temperature  Pickup Lat  Pickup Long  Destination Lat  \\\n",
       "5593              8         22.5   -1.300921    36.828195        -1.258711   \n",
       "6873              5         23.2   -1.260234    36.799055        -1.256810   \n",
       "\n",
       "      Destination Long  No_Of_Orders  Age  Average_Rating  No_of_Ratings  \\\n",
       "5593         36.834940           282  326            14.7             46   \n",
       "6873         36.773083           235  740            13.5             24   \n",
       "\n",
       "      Arrival at Pickup - Time_sin(seconds)  \\\n",
       "5593                              -0.674732   \n",
       "6873                               0.411846   \n",
       "\n",
       "      Arrival at Pickup - Time_cos(seconds)  Platform Type_2  Platform Type_3  \\\n",
       "5593                              -0.738063              0.0              1.0   \n",
       "6873                              -0.911254              0.0              1.0   \n",
       "\n",
       "      Platform Type_4  Personal or Business_Personal  \\\n",
       "5593              0.0                            0.0   \n",
       "6873              0.0                            0.0   \n",
       "\n",
       "      Arrival at Pickup - Day of Month_sin(day)  \\\n",
       "5593                                   0.724793   \n",
       "6873                                   0.998717   \n",
       "\n",
       "      Arrival at Pickup - Day of Month_cos(day)  \\\n",
       "5593                                   0.688967   \n",
       "6873                                  -0.050649   \n",
       "\n",
       "      Arrival at Pickup - Weekday (Mo = 1)_sin(day)  \\\n",
       "5593                                       0.974928   \n",
       "6873                                      -0.974928   \n",
       "\n",
       "      Arrival at Pickup - Weekday (Mo = 1)_cos(day)  \n",
       "5593                                      -0.222521  \n",
       "6873                                      -0.222521  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'day' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-766a634e4130>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mday\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'day' is not defined"
     ]
    }
   ],
   "source": [
    "day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = cleaner(X_test, day_of_month_cols=day_of_month_cols, day_of_week_cols=day_of_week_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropped by corr ['Pickup - Time_sin(seconds)', 'Pickup - Time_cos(seconds)', 'Pickup - Day of Month_sin(day)', 'Pickup - Day of Month_cos(day)', 'Pickup - Weekday (Mo = 1)_sin(day)', 'Pickup - Weekday (Mo = 1)_cos(day)']\n",
      "Total of 10 original columns dropped \n",
      "\n",
      "Total of 10 new CLEAN columns formed \n",
      "\n",
      "Dataframe now has 20 from 20 input columns\n",
      "['Vehicle Type', 'Platform Type', 'Personal or Business', 'Arrival at Pickup - Day of Month', 'Arrival at Pickup - Weekday (Mo = 1)', 'Arrival at Pickup - Time', 'Pickup - Day of Month', 'Pickup - Weekday (Mo = 1)', 'Pickup - Time', 'Precipitation in millimeters']\n"
     ]
    }
   ],
   "source": [
    "X1 = cleaner(X, day_of_month_cols=day_of_month_cols, day_of_week_cols=day_of_week_cols) # When we want to create a cross validation model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We must also apply it on our finial test: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_test = cleaner(f_testx, day_of_month_cols=day_of_month_cols, day_of_week_cols=day_of_week_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = X_train.corr(method = \"spearman\").abs()\n",
    "sns.set(font_scale = 1.0)\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "sns.heatmap(corr_matrix, cmap= \"YlGnBu\", square=True, ax = ax)\n",
    "f.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import Lasso, Ridge, LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "polinomial_features = PolynomialFeatures(2)\n",
    "# Construct the pipeline with a standard scaler and a small neural network\n",
    "models = [Lasso(alpha=0.1), Ridge(), LinearRegression()]\n",
    "for mod in models:\n",
    "    estimators = []\n",
    "    estimators.append(('imputer', SimpleImputer(strategy='median')))\n",
    "    estimators.append(('standardize', StandardScaler()))\n",
    "    estimators.append(('plf', polinomial_features))\n",
    "    estimators.append(('mod', mod))\n",
    "    model = Pipeline(estimators)\n",
    "\n",
    "    # To begin, let's use only these two features to predict 'cnt' (bicycle count)\n",
    "\n",
    "    # We'll use 5-fold cross validation. That is, a random 80% of the data will be used\n",
    "    # to train the model, and the prediction score will be computed on the remaining 20%.\n",
    "    # This process is repeated five times such that the training sets in each \"fold\"\n",
    "    # are mutually orthogonal.\n",
    "    from sklearn.model_selection import KFold\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    kfold = KFold(n_splits=5)\n",
    "\n",
    "    results = cross_val_score(model, X1, y, cv=kfold, scoring='neg_mean_squared_error')\n",
    "    print(mod)\n",
    "    print ('CV Scoring Result: mean=',np.sqrt(abs(np.mean(results))),'std=',np.std(results))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('counts')\n",
    "p1 = 0\n",
    "for i in range(len(X1['Platform Type_2'])):\n",
    "    if (X1['Platform Type_2'][i] == X1['Platform Type_3'][i]) == (X1['Platform Type_4'][i] == 0):\n",
    "        p1 += 1\n",
    "\n",
    "p2 = sum(X1['Platform Type_2'] == 1)\n",
    "p3 = sum(X1['Platform Type_3'] == 1)\n",
    "p4 = sum(X1['Platform Type_4'] == 1)\n",
    "\n",
    "print('Platform Type_1: ', p1)\n",
    "print('Platform Type_2: ', sum(X1['Platform Type_2'] == 1))\n",
    "print('Platform Type_3: ', sum(X1['Platform Type_3'] == 1))\n",
    "print('Platform Type_4: ', sum(X1['Platform Type_4'] == 1))\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print('propotions')\n",
    "print('total = ', sum([p1,p2,p3,p4]))\n",
    "for value in [p1,p2,p3,p4]:\n",
    "    print(round(value * 100/sum([p1,p2,p3,p4]), 2))\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('counts')\n",
    "\n",
    "personal = sum(X1['Personal or Business_Personal'] == 1)\n",
    "business = sum(X1['Personal or Business_Personal'] != 1)\n",
    "print('personal: ', personal, '\\nbusiness: ', business, '\\n')\n",
    "print('propotions')\n",
    "for value in [personal, business]:\n",
    "    print(round(value * 100/sum([personal, business]), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('counts')\n",
    "p1 = 0\n",
    "for i in range(len(F_test['Platform Type_2'])):\n",
    "    if (F_test['Platform Type_2'][i] == F_test['Platform Type_3'][i]) == (F_test['Platform Type_4'][i] == 0):\n",
    "        p1 += 1\n",
    "\n",
    "p2 = sum(F_test['Platform Type_2'] == 1)\n",
    "p3 = sum(F_test['Platform Type_3'] == 1)\n",
    "p4 = sum(F_test['Platform Type_4'] == 1)\n",
    "\n",
    "print('Platform Type_1: ', p1)\n",
    "print('Platform Type_2: ', sum(F_test['Platform Type_2'] == 1))\n",
    "print('Platform Type_3: ', sum(F_test['Platform Type_3'] == 1))\n",
    "print('Platform Type_4: ', sum(F_test['Platform Type_4'] == 1))\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print('propotions')\n",
    "print('total = ', sum([p1,p2,p3,p4]))\n",
    "for value in [p1,p2,p3,p4]:\n",
    "    print(round(value * 100/sum([p1,p2,p3,p4]), 2))\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([X1, y], axis=1)\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['Temperature']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(X1['Temperature'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxenplot(X1['Temperature'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('mean: ', data['Temperature'].mean())\n",
    "print('median: ', data['Temperature'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Temperature'].fillna(data['Temperature'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs = data.corr()['Time from Pickup to Arrival'].sort_values(ascending=False)\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Build a dictionary of correlation coefficients and p-values\n",
    "dict_cp = {}\n",
    "\n",
    "column_titles = [col for col in corrs.index if col!= 'Time from Pickup to Arrival']\n",
    "for col in column_titles:\n",
    "    p_val = round(pearsonr(data[col], data['Time from Pickup to Arrival'])[1],6)\n",
    "    dict_cp[col] = {'Correlation_Coefficient':corrs[col],\n",
    "                    'P_Value':p_val}\n",
    "\n",
    "df_cp = pd.DataFrame(dict_cp).T\n",
    "df_cp_sorted = df_cp.sort_values('P_Value')\n",
    "df_cp_sorted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = df_cp_sorted[df_cp_sorted['P_Value'] > 0.1].index\n",
    "X_train2 = X_train.drop(columns=to_drop)\n",
    "X_test2 = X_test.drop(columns=to_drop)\n",
    "F_test2 = F_test.drop(columns=to_drop)\n",
    "X2 = X1.drop(columns=to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = X_train2.corr(method = \"spearman\").abs()\n",
    "sns.set(font_scale = 1.0)\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "sns.heatmap(corr_matrix, cmap= \"YlGnBu\", square=True, ax = ax)\n",
    "f.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import Lasso, Ridge, LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "polinomial_features = PolynomialFeatures(2)\n",
    "# Construct the pipeline with a standard scaler and a small neural network\n",
    "models = [Lasso(alpha=0.1), Ridge(), LinearRegression()]\n",
    "for mod in models:\n",
    "    estimators = []\n",
    "    estimators.append(('imputer', SimpleImputer(strategy='median')))\n",
    "    estimators.append(('standardize', StandardScaler()))\n",
    "    estimators.append(('plf', polinomial_features))\n",
    "    estimators.append(('mod', mod))\n",
    "    model = Pipeline(estimators)\n",
    "\n",
    "    # To begin, let's use only these two features to predict 'cnt' (bicycle count)\n",
    "\n",
    "    # We'll use 5-fold cross validation. That is, a random 80% of the data will be used\n",
    "    # to train the model, and the prediction score will be computed on the remaining 20%.\n",
    "    # This process is repeated five times such that the training sets in each \"fold\"\n",
    "    # are mutually orthogonal.\n",
    "    from sklearn.model_selection import KFold\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    kfold = KFold(n_splits=5)\n",
    "\n",
    "    results = cross_val_score(model, X1, y, cv=kfold, scoring='neg_mean_squared_error')\n",
    "    print(mod)\n",
    "    print ('CV Scoring Result: mean=',np.sqrt(abs(np.mean(results))),'std=',np.std(results))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data is ready"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will standardize the columns which have a max absolute value that is greater than 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X1)\n",
    "X_normalize = pd.DataFrame(X_scaled, columns=X1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_normalize.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "# Create VarianceThreshold object\n",
    "selector = VarianceThreshold(threshold=0.03)\n",
    "\n",
    "# Use the object to apply the threshold on data\n",
    "selector.fit(X_normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get column variances\n",
    "column_variances = selector.variances_\n",
    "\n",
    "vars_dict = {}\n",
    "vars_dict = [{\"Variable_Name\": c_name, \"Variance\": c_var}\n",
    "             for c_name, c_var in zip(X_normalize.columns, column_variances)]\n",
    "df_vars = pd.DataFrame(vars_dict)\n",
    "df_vars.sort_values(by='Variance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowvar = np.array(df_vars.loc[range(8)]['Variable_Name'])\n",
    "lowvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hivar = np.array(df_vars.loc[range(8, 19)]['Variable_Name'])\n",
    "hivar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select new columns\n",
    "X_new = X_normalize[X_normalize.columns[selector.get_support(indices=True)]]\n",
    "\n",
    "# Save variable names for later\n",
    "X_var_names = X_new.columns\n",
    "\n",
    "# View first few entries\n",
    "X_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector.transform(X_normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = data[(data['Platform Type_4'] != 1) | (data['Platform Type_2'] != 1) | (data['Time from Pickup to Arrival'] > 60)].drop(columns=['Arrival at Pickup - Time_sin(seconds)',\n",
    "       'Arrival at Pickup - Time_cos(seconds)'])\n",
    "y_r_dropped = d.iloc[:, -1]\n",
    "X_r_dropped = d.iloc[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(data['Time from Pickup to Arrival'])[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<catboost.core.CatBoostRegressor object at 0x0000020B1D2397F0>\n",
      "CV Scoring Result: mean= 746.1454097405029 std = 21.013119269319994 list of values = [720.8251656959673, 728.2803994455254, 744.6509352073026, 755.2440619968804, 780.2467521113456]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures, Normalizer\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, BaggingRegressor, AdaBoostRegressor\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "polinomial_features = PolynomialFeatures(1)\n",
    "# Construct the pipeline with a standard scaler and a small neural network\n",
    "models = [CatBoostRegressor(verbose=0)]\n",
    "for mod in models:\n",
    "    estimators = []\n",
    "    estimators.append(('imputer', SimpleImputer(strategy='median')))\n",
    "    estimators.append(('standardize', StandardScaler()))\n",
    "    estimators.append(('plf', polinomial_features))\n",
    "    estimators.append(('mod', mod))\n",
    "    model = Pipeline(estimators)\n",
    "\n",
    "    # To begin, let's use only these two features to predict 'cnt' (bicycle count)\n",
    "\n",
    "    # We'll use 5-fold cross validation. That is, a random 80% of the data will be used\n",
    "    # to train the model, and the prediction score will be computed on the remaining 20%.\n",
    "    # This process is repeated five times such that the training sets in each \"fold\"\n",
    "    # are mutually orthogonal.\n",
    "    from sklearn.model_selection import KFold\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    kfold = KFold(n_splits=5)\n",
    "\n",
    "    results = cross_val_score(model, X1.to_numpy(), y, cv=kfold, scoring='neg_mean_squared_error')\n",
    "    print(mod)\n",
    "    print ('CV Scoring Result: mean=',np.sqrt(abs(np.mean(results))),'std =', np.std(sorted(np.sqrt(-np.array(results)))),'list of values =',sorted(np.sqrt(-np.array(results))))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = X1.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Distance (KM)</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Pickup Lat</th>\n",
       "      <th>Pickup Long</th>\n",
       "      <th>Destination Lat</th>\n",
       "      <th>Destination Long</th>\n",
       "      <th>No_Of_Orders</th>\n",
       "      <th>Age</th>\n",
       "      <th>Average_Rating</th>\n",
       "      <th>No_of_Ratings</th>\n",
       "      <th>Arrival at Pickup - Time_sin(seconds)</th>\n",
       "      <th>Arrival at Pickup - Time_cos(seconds)</th>\n",
       "      <th>Platform Type_2</th>\n",
       "      <th>Platform Type_3</th>\n",
       "      <th>Platform Type_4</th>\n",
       "      <th>Personal or Business_Personal</th>\n",
       "      <th>Arrival at Pickup - Day of Month_sin(day)</th>\n",
       "      <th>Arrival at Pickup - Day of Month_cos(day)</th>\n",
       "      <th>Arrival at Pickup - Weekday (Mo = 1)_sin(day)</th>\n",
       "      <th>Arrival at Pickup - Weekday (Mo = 1)_cos(day)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>20.4</td>\n",
       "      <td>-1.317755</td>\n",
       "      <td>36.83037</td>\n",
       "      <td>-1.300406</td>\n",
       "      <td>36.829741</td>\n",
       "      <td>1637</td>\n",
       "      <td>1309</td>\n",
       "      <td>13.8</td>\n",
       "      <td>549</td>\n",
       "      <td>0.481817</td>\n",
       "      <td>-0.876272</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.968077</td>\n",
       "      <td>-0.250653</td>\n",
       "      <td>-0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Distance (KM)  Temperature  Pickup Lat  Pickup Long  Destination Lat  \\\n",
       "0              4         20.4   -1.317755     36.83037        -1.300406   \n",
       "\n",
       "   Destination Long  No_Of_Orders   Age  Average_Rating  No_of_Ratings  \\\n",
       "0         36.829741          1637  1309            13.8            549   \n",
       "\n",
       "   Arrival at Pickup - Time_sin(seconds)  \\\n",
       "0                               0.481817   \n",
       "\n",
       "   Arrival at Pickup - Time_cos(seconds)  Platform Type_2  Platform Type_3  \\\n",
       "0                              -0.876272              0.0              1.0   \n",
       "\n",
       "   Platform Type_4  Personal or Business_Personal  \\\n",
       "0              0.0                            0.0   \n",
       "\n",
       "   Arrival at Pickup - Day of Month_sin(day)  \\\n",
       "0                                   0.968077   \n",
       "\n",
       "   Arrival at Pickup - Day of Month_cos(day)  \\\n",
       "0                                  -0.250653   \n",
       "\n",
       "   Arrival at Pickup - Weekday (Mo = 1)_sin(day)  \\\n",
       "0                                      -0.974928   \n",
       "\n",
       "   Arrival at Pickup - Weekday (Mo = 1)_cos(day)  \n",
       "0                                      -0.222521  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = []\n",
    "polinomial_features = PolynomialFeatures(1)\n",
    "estimators.append(('imputer', SimpleImputer(strategy='median')))\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('plf', polinomial_features))\n",
    "estimators.append(('mod', CatBoostRegressor(verbose=0)))\n",
    "model = Pipeline(estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('imputer', SimpleImputer(strategy='median')),\n",
       "                ('standardize', StandardScaler()),\n",
       "                ('plf', PolynomialFeatures(degree=1)),\n",
       "                ('mod',\n",
       "                 <catboost.core.CatBoostRegressor object at 0x0000020B1D239908>)])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# v1 = sample.copy()\n",
    "model.fit(X1.to_numpy(), y)\n",
    "# y_pred = model.predict(F_test)\n",
    "# v1['Order_No'] = finaltest['Order No']\n",
    "# v1['Time from Pickup to Arrival'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1.to_csv('catboost1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "model_save_path = \"cat_model.pkl\"\n",
    "with open(model_save_path,'wb') as file:\n",
    "    pickle.dump(model, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in [col for col in data.columns if col!= 'Time from Pickup to Arrival']:\n",
    "#     plt.plot(x, 'Time from Pickup to Arrival', data=data)\n",
    "# plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures, Normalizer\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sklearn_kfold_split(data,K):\n",
    "    kf = KFold(n_splits=K, shuffle=False)\n",
    "\n",
    "    \n",
    "    return [(datatr, datate) for datatr, datate in kf.split(data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(data.iloc[:,:-1])\n",
    "X_normalize = pd.DataFrame(X_scaled, columns=data.iloc[:,:-1].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.concat([X_normalize, data.iloc[:,-1]], axis=1)\n",
    "F_test3 = F_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = sklearn_kfold_split(data2, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_k_model(data,data_indices):\n",
    "    models = [Lasso(alpha=0.1), LinearRegression(), RandomForestRegressor(random_state=42)]\n",
    "    # polinomial_features = PolynomialFeatures(pol_f)\n",
    "    d = {}\n",
    "    rmses = []\n",
    "    for pol_f in [1,2]:\n",
    "        polinomial_features = PolynomialFeatures(pol_f)\n",
    "        for mod in models:\n",
    "            print('polinomial_features', polinomial_features)\n",
    "            print(2*'\\n', mod)\n",
    "            for row in data_indices:\n",
    "                estimator = []\n",
    "                X_train, y_train = data[row[0], :-1], data[row[0], -1]\n",
    "                X_test, y_test = data[row[1], :-1], data[row[1], -1]\n",
    "                #rf = RandomForestRegressor(random_state=42)\n",
    "                estimator.append(('imputer', SimpleImputer(strategy='median')))\n",
    "                estimator.append(('scaler', MinMaxScaler()))\n",
    "                estimator.append(('pf', polinomial_features))\n",
    "                estimator.append(('model', mod))\n",
    "                rf = Pipeline(estimator)\n",
    "                #rf = Lasso(())\n",
    "                rf.fit(X_train.reshape(-1, 1), y_train)\n",
    "                mse = mean_squared_error(y_test, rf.predict(X_test.reshape(-1, 1)))\n",
    "                rmse =  np.sqrt(mse)\n",
    "                print (mse)\n",
    "                print('rmse =', np.sqrt(mse), '\\n')\n",
    "                rmses.append(rmse)\n",
    "                d[rmse] = rf\n",
    "\n",
    "\n",
    "    print('\\nbest score = ', min(rmses) , '\\nby :', d[min(rmses)])\n",
    "    return d[min(rmses)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = best_k_model(data.drop(columns=['No_Of_Orders', 'Age', 'Temperature']).values, ind)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polinomial_features = PolynomialFeatures(1)\n",
    "estimator = []\n",
    "estimator.append(('imputer', SimpleImputer(strategy='median')))\n",
    "estimator.append(('scaler', MinMaxScaler()))\n",
    "estimator.append(('pf', polinomial_features))\n",
    "estimator.append(('model', RandomForestRegressor(random_state=42)))\n",
    "rf = Pipeline(estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(X1.drop(columns=['No_Of_Orders', 'Age', 'Temperature']), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.predict(F_test3.drop(columns=['No_Of_Orders', 'Age', 'Temperature']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf.predict(F_test3.drop(columns=['No_Of_Orders', 'Age', 'Temperature']))\n",
    "v1['Order_No'] = finaltest['Order No']\n",
    "v1['Time from Pickup to Arrival'] = y_pred\n",
    "v1.to_csv('best_with_temp4rfsunday648pm.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(F_test3)\n",
    "v1['Order_No'] = finaltest['Order No']\n",
    "v1['Time from Pickup to Arrival'] = y_pred\n",
    "v1.to_csv('best_without_temp3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(F_test3.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(data2.columns) - set(F_test3.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(F_test3.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model._check_n_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures, Normalizer\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "polinomial_features = PolynomialFeatures(1)\n",
    "# Construct the pipeline with a standard scaler and a small neural network\n",
    "models = [Lasso(alpha=0.1), LinearRegression(), RandomForestRegressor(random_state=42)]\n",
    "for mod in models:\n",
    "    estimators = []\n",
    "    estimators.append(('imputer', SimpleImputer(strategy='median')))\n",
    "    estimators.append(('standardize', StandardScaler()))\n",
    "    estimators.append(('plf', polinomial_features))\n",
    "    estimators.append(('mod', mod))\n",
    "    model = Pipeline(estimators)\n",
    "\n",
    "    # To begin, let's use only these two features to predict 'cnt' (bicycle count)\n",
    "\n",
    "    # We'll use 5-fold cross validation. That is, a random 80% of the data will be used\n",
    "    # to train the model, and the prediction score will be computed on the remaining 20%.\n",
    "    # This process is repeated five times such that the training sets in each \"fold\"\n",
    "    # are mutually orthogonal.\n",
    "    from sklearn.model_selection import KFold\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    kfold = KFold(n_splits=5)\n",
    "\n",
    "    results = cross_val_score(model, X1.drop(columns=['No_Of_Orders', 'Age', 'Temperature']), y, cv=kfold, scoring='neg_mean_squared_error')\n",
    "    print(mod)\n",
    "    print ('CV Scoring Result: mean=',np.sqrt(abs(np.mean(results))),'std=',np.std(results))\n",
    "    print('\\n')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMuW28rZFUbkQlqjGk0nZFk",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "sam_regression.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
